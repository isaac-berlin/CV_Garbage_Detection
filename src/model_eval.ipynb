{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Dataset and trainsform it into a hugingface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import supervision as sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the dataset as a supervision dataset in coco format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = r\"C:\\Users\\isaac\\dev\\CV_Garbage_Detection\\Data\"\n",
    "\n",
    "ds_train = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=os.path.join(ds_path, \"train\"),\n",
    "    annotations_path=os.path.join(ds_path, \"train\", \"_annotations.coco.json\"),\n",
    ")\n",
    "\n",
    "ds_test = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=os.path.join(ds_path, \"test\"),\n",
    "    annotations_path=os.path.join(ds_path, \"test\", \"_annotations.coco.json\"),\n",
    ")\n",
    "\n",
    "ds_valid = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=os.path.join(ds_path, \"valid\"),\n",
    "    annotations_path=os.path.join(ds_path, \"valid\", \"_annotations.coco.json\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper functions for the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sv_to_custom_format(sv_dataset, class_mapping=None):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "    widths = []\n",
    "    heights = []\n",
    "    objects = []\n",
    "        \n",
    "    image_id = 0\n",
    "    for path, image, detections in sv_dataset:\n",
    "        # Load image\n",
    "        img = Image.open(path)\n",
    "        images.append(img)\n",
    "        image_ids.append(image_id)\n",
    "        width, height = (416, 416)\n",
    "        widths.append(width)\n",
    "        heights.append(height)\n",
    "        \n",
    "        # Process detections\n",
    "        object_ids = []\n",
    "        bboxes = []\n",
    "        areas = []\n",
    "        categories = []\n",
    "\n",
    "        for detection in detections:\n",
    "            x_min, y_min, x_max, y_max = detection[0]  # Supervision bounding box\n",
    "            bbox = [x_min, y_min, x_max - x_min, y_max - y_min]\n",
    "            area = (x_max - x_min) * (y_max - y_min)  # Compute area\n",
    "            category = class_mapping[detection[3]] if class_mapping else str(detection[3])\n",
    "            object_ids.append(detection[3])\n",
    "\n",
    "            bboxes.append(bbox)\n",
    "            areas.append(area)\n",
    "            categories.append(category)\n",
    "\n",
    "        objects.append({\n",
    "            \"id\": object_ids,\n",
    "            \"bbox\": bboxes,\n",
    "            \"area\": areas,\n",
    "            \"category\": categories\n",
    "        })\n",
    "        \n",
    "        image_id += 1\n",
    "\n",
    "    formatted_data = {\n",
    "        \"image\": images,\n",
    "        \"image_id\": image_ids,\n",
    "        \"width\": widths,\n",
    "        \"height\": heights,\n",
    "        \"objects\": objects\n",
    "    }\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_mappings_from_coco(annotation_path):\n",
    "    with open(annotation_path, \"r\") as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # Extract categories\n",
    "    categories = coco_data[\"categories\"]\n",
    "    class_mapping = {category[\"id\"]: category[\"name\"] for category in categories}\n",
    "    return class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mappings = get_class_mappings_from_coco(os.path.join(ds_path, \"train\", \"_annotations.coco.json\"))\n",
    "label2id = {v: k for k, v in class_mappings.items()}\n",
    "id2label = {k: v for k, v in class_mappings.items()}\n",
    "\n",
    "formatted_train = sv_to_custom_format(ds_train, class_mappings)\n",
    "formatted_test = sv_to_custom_format(ds_test, class_mappings)\n",
    "formatted_valid = sv_to_custom_format(ds_valid, class_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the dataset into a huggingface dataset using the created dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict(formatted_train)\n",
    "test_dataset = Dataset.from_dict(formatted_test)\n",
    "valid_dataset = Dataset.from_dict(formatted_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the model and create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForObjectDetection, AutoImageProcessor, pipeline\n",
    "\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"isaacberlin/conditional-detr-resnet-50-TACO-finetuned\")\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/conditional-detr-resnet-50\")\n",
    "\n",
    "pipe = pipeline(\"object-detection\", model=model, image_processor=image_processor, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turn predictions into usable format for coco evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "for item in test_dataset:\n",
    "    image = item[\"image\"]  \n",
    "    image_id = item[\"image_id\"]         \n",
    "    outputs = pipe(image)\n",
    "    for output in outputs:\n",
    "        box = output[\"box\"]\n",
    "        x_min, y_min, x_max, y_max = box.values()\n",
    "        all_predictions.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": label2id[output[\"label\"]],\n",
    "            \"bbox\": [x_min, y_min, x_max - x_min, y_max - y_min],\n",
    "            \"score\": output[\"score\"]\n",
    "        })\n",
    "        \n",
    "with open(\"predictions.json\", \"w\") as f:\n",
    "    json.dump(all_predictions, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Based on coco evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_gt = COCO(os.path.join(ds_path, \"test\", \"_annotations.coco.json\"))\n",
    "coco_dt = coco_gt.loadRes(\"predictions.json\")\n",
    "\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, iouType=\"bbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.301\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.516\n"
     ]
    }
   ],
   "source": [
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Precision and Recall based on coco evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision (AP): 0.2343\n",
      "Average Recall (AR): 0.2695\n"
     ]
    }
   ],
   "source": [
    "# Average Precision (AP) and Average Recall (AR)\n",
    "ap = coco_eval.stats[0]  # AP@[IoU=0.50:0.95]\n",
    "ar = coco_eval.stats[8]  # AR@[IoU=0.50:0.95]\n",
    "\n",
    "print(f\"Average Precision (AP): {ap:.4f}\")\n",
    "print(f\"Average Recall (AR): {ar:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCI5561",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
